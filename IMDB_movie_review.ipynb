{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IQSQU3n3RDqA"
      },
      "outputs": [],
      "source": [
        "# Open the original CSV file\n",
        "with open('IMDB.csv', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Filter out problematic lines\n",
        "filtered_lines = [line for line in lines if len(line.split(',')) == 2]\n",
        "\n",
        "# Save the filtered lines to a new CSV file\n",
        "with open('filtered.csv', 'w', encoding='utf-8') as file:\n",
        "    file.writelines(filtered_lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cT5JGojAZeJr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "df = pd.read_csv('filtered.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pax3AyRUZipa",
        "outputId": "76edcf77-c27e-4f9d-d6c1-c20a190788dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    fantastic movie three prisoner become famous ....\n",
            "1    worst movie saw worldfest also received least ...\n",
            "2    protocol implausible movie whose saving grace ...\n",
            "3    unmarried woman named stella ( bette midler ) ...\n",
            "4    probably worst movie ever seen life ! ! stupid...\n",
            "5    oh no one attack japanese ghost girl movie ......\n",
            "6    's terrific funny movie n't make smile . pity ...\n",
            "7    one finest movie ever seen .... stark scenery ...\n",
            "8    movie get 10 lot gore it.who care plot acting....\n",
            "9    movie well directed . almost totally disregard...\n",
            "Name: Preprocessed_Text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "  if isinstance(text, str):\n",
        "    text = re.sub('<[^<]+?>', ' ', text)\n",
        "    text = text.lower()\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text\n",
        "  else:\n",
        "      return ''\n",
        "\n",
        "df['Preprocessed_Text'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "print(df['Preprocessed_Text'].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG37g_5vZyeh",
        "outputId": "59b6eb96-95ea-4f5d-8121-6a7324b78ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of TF-IDF matrix: (165, 1000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['Preprocessed_Text'])\n",
        "\n",
        "print(\"Shape of TF-IDF matrix:\", X_tfidf.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRmL4qWiZ1mj",
        "outputId": "fff8f463-49c6-4a6a-95b9-723c7401f088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature names: ['10' '100' '16' '17' '25' '30' '42' '80' '90' 'abbey' 'ability' 'able'\n",
            " 'absolutely' 'accident' 'account' 'accuracy' 'achievement' 'acid'\n",
            " 'across' 'act' 'acted' 'acting' 'action' 'actor' 'actress' 'actual'\n",
            " 'actually' 'add' 'added' 'addict' 'advice' 'advise' 'afternoon'\n",
            " 'afterwards' 'agent' 'ago' 'air' 'alien' 'almost' 'alone' 'along'\n",
            " 'already' 'also' 'although' 'always' 'amazing' 'american' 'amitabh'\n",
            " 'amount' 'amuses' 'annoying' 'another' 'anymore' 'anyone' 'anything'\n",
            " 'anyway' 'apart' 'appeal' 'appearance' 'appears' 'applause' 'appreciate'\n",
            " 'archie' 'argument' 'ariauna' 'around' 'art' 'asked' 'assaulted'\n",
            " 'attempt' 'attractive' 'audience' 'australian' 'average' 'avoid' 'award'\n",
            " 'away' 'awful' 'back' 'bad' 'badly' 'banker' 'based' 'bat' 'beautiful'\n",
            " 'became' 'become' 'becomes' 'bed' 'beginning' 'behind' 'believe' 'best'\n",
            " 'better' 'big' 'bike' 'bill' 'birthday' 'bit' 'black' 'blah' 'bollywood'\n",
            " 'book' 'bored' 'boring' 'box' 'boy' 'boyfriend' 'break' 'brings'\n",
            " 'british' 'brother' 'buddy' 'budget' 'bunch' 'business' 'buster' 'buy'\n",
            " 'ca' 'call' 'called' 'came' 'cameo' 'cant' 'captured' 'car' 'card' 'care'\n",
            " 'case' 'cast' 'casting' 'caught' 'cave' 'certainly' 'chan' 'channel'\n",
            " 'character' 'charm' 'chavez' 'cheap' 'check' 'child' 'christmas' 'chucky'\n",
            " 'cinema' 'cinematography' 'circumstance' 'classic' 'clear' 'clearly'\n",
            " 'come' 'comedian' 'comedy' 'comic' 'comment' 'completely' 'confused'\n",
            " 'confusing' 'consider' 'contain' 'cool' 'cop' 'copy' 'coroner' 'cost'\n",
            " 'could' 'count' 'country' 'couple' 'cousin' 'cox' 'crap' 'crazy' 'create'\n",
            " 'created' 'creature' 'credit' 'creepy' 'crew' 'cry' 'cult' 'dad' 'date'\n",
            " 'day' 'de' 'dead' 'deal' 'dealing' 'dean' 'deanna' 'decent' 'definitely'\n",
            " 'depth' 'deserve' 'detail' 'development' 'dialog' 'died' 'different'\n",
            " 'directed' 'direction' 'director' 'disappointed' 'disappointing'\n",
            " 'documentary' 'doesnt' 'dollar' 'done' 'dont' 'door' 'doubt' 'drama'\n",
            " 'dream' 'dress' 'driver' 'drug' 'dull' 'dvd' 'early' 'easily' 'easy'\n",
            " 'eddie' 'editing' 'effect' 'either' 'end' 'ending' 'english' 'enjoy'\n",
            " 'enjoyable' 'enjoyed' 'enough' 'entertaining' 'entertainment' 'entire'\n",
            " 'episode' 'especially' 'etc' 'even' 'event' 'ever' 'every' 'everyone'\n",
            " 'everything' 'evil' 'example' 'excellent' 'except' 'excuse' 'exists'\n",
            " 'expect' 'expected' 'expecting' 'experience' 'extent' 'extraordinary'\n",
            " 'extremely' 'face' 'facility' 'fact' 'fairly' 'fake' 'fall' 'fame'\n",
            " 'family' 'famous' 'fan' 'fantastic' 'far' 'fashion' 'fat' 'father'\n",
            " 'favor' 'favorite' 'favourite' 'fbi' 'feature' 'feel' 'feeling' 'fell'\n",
            " 'felt' 'female' 'fest' 'festival' 'fetish' 'fi' 'fiction' 'fight'\n",
            " 'fighting' 'fill' 'film' 'filmed' 'finally' 'find' 'fine' 'finish'\n",
            " 'finished' 'fired' 'first' 'fit' 'five' 'flashback' 'flat' 'flaw' 'fly'\n",
            " 'flying' 'flynn' 'focus' 'folk' 'following' 'footage' 'football' 'forget'\n",
            " 'form' 'forward' 'found' 'france' 'frankly' 'french' 'friend'\n",
            " 'friendship' 'frits' 'full' 'fully' 'fun' 'funniest' 'funny' 'gag' 'game'\n",
            " 'garbage' 'garth' 'gave' 'gay' 'gee' 'gene' 'generally' 'genius' 'george'\n",
            " 'gere' 'get' 'getting' 'girl' 'girlfriend' 'give' 'given' 'glad' 'go'\n",
            " 'god' 'going' 'goldie' 'golf' 'good' 'goodness' 'gore' 'gorgeous' 'got'\n",
            " 'government' 'grabbed' 'grace' 'graphic' 'great' 'greatest' 'grew'\n",
            " 'grinch' 'guess' 'gun' 'guy' 'ha' 'hair' 'haka' 'half' 'hall' 'hand'\n",
            " 'happen' 'happened' 'happens' 'happy' 'hard' 'hardly' 'hasn' 'hate'\n",
            " 'hawn' 'hbo' 'head' 'headmaster' 'hear' 'heard' 'heart' 'helena' 'help'\n",
            " 'helped' 'hero' 'hide' 'hiding' 'high' 'highly' 'hiker' 'hilarious'\n",
            " 'hill' 'history' 'hit' 'hitch' 'hitler' 'hk' 'hole' 'hollywood' 'home'\n",
            " 'homicide' 'hong' 'hope' 'hoping' 'hopper' 'horrible' 'horror' 'hospital'\n",
            " 'hot' 'hour' 'house' 'however' 'human' 'humor' 'humorous' 'humour'\n",
            " 'hunter' 'hurt' 'husband' 'id' 'idea' 'idiot' 'ie' 'image' 'imagine'\n",
            " 'immediately' 'important' 'impressed' 'impressive' 'incredible'\n",
            " 'incredibly' 'india' 'indian' 'infected' 'influence' 'information'\n",
            " 'inside' 'inspiring' 'instead' 'intense' 'intention' 'interest'\n",
            " 'interested' 'interesting' 'international' 'interpretation' 'intriguing'\n",
            " 'involved' 'irish' 'it' 'italian' 'jack' 'jackie' 'jail' 'james' 'japan'\n",
            " 'japanese' 'jay' 'jazz' 'jhoom' 'job' 'joe' 'john' 'joke' 'jonathon'\n",
            " 'judge' 'juice' 'juliana' 'juliet' 'junk' 'justice' 'kar' 'keep'\n",
            " 'keeping' 'kept' 'key' 'khan' 'kick' 'kid' 'kiera' 'kill' 'killed'\n",
            " 'killer' 'killing' 'kind' 'kiss' 'knew' 'know' 'kong' 'kurt' 'lack'\n",
            " 'lacked' 'lame' 'language' 'last' 'late' 'later' 'laugh' 'laughable'\n",
            " 'laughed' 'laughing' 'law' 'le' 'lead' 'learn' 'learning' 'least' 'leave'\n",
            " 'leaving' 'left' 'leg' 'leguizamo' 'leper' 'lesson' 'let' 'life' 'like'\n",
            " 'liked' 'limo' 'line' 'lip' 'little' 'live' 'living' 'll' 'local' 'long'\n",
            " 'look' 'looked' 'looking' 'loose' 'loses' 'lost' 'lot' 'loud' 'love'\n",
            " 'loved' 'low' 'luzhin' 'macintosh' 'made' 'madsen' 'main' 'mainly'\n",
            " 'major' 'make' 'maker' 'making' 'male' 'maltin' 'man' 'managed' 'manner'\n",
            " 'many' 'marine' 'mark' 'married' 'martian' 'matter' 'may' 'maybe' 'mean'\n",
            " 'meaningless' 'medium' 'meet' 'member' 'men' 'messing' 'middle' 'midler'\n",
            " 'might' 'million' 'mind' 'minute' 'missed' 'mistake' 'moment' 'money'\n",
            " 'mood' 'moral' 'mother' 'movie' 'moving' 'mr' 'much' 'murder' 'murphy'\n",
            " 'music' 'must' 'mystery' 'nabokov' 'nagra' 'name' 'named' 'nearly' 'ned'\n",
            " 'need' 'needed' 'negative' 'never' 'new' 'next' 'nice' 'night' 'non'\n",
            " 'nothing' 'novel' 'nowhere' 'nt' 'nudity' 'number' 'obvious' 'obviously'\n",
            " 'off' 'oh' 'ok' 'old' 'one' 'open' 'opening' 'opinion' 'original' 'orry'\n",
            " 'os' 'oscar' 'others' 'outstanding' 'paid' 'painful' 'pang' 'parent'\n",
            " 'parody' 'part' 'particularly' 'party' 'past' 'pay' 'pembleton' 'people'\n",
            " 'perfect' 'performance' 'period' 'person' 'phantom' 'phone' 'picked'\n",
            " 'picture' 'piece' 'pity' 'place' 'play' 'played' 'playing' 'please'\n",
            " 'plot' 'point' 'poker' 'poor' 'poorly' 'pop' 'portrayed' 'positive'\n",
            " 'possible' 'power' 'powerful' 'predictably' 'prefer' 'pregnant' 'preston'\n",
            " 'pretentious' 'pretty' 'price' 'principal' 'probably' 'problem'\n",
            " 'producer' 'production' 'project' 'proper' 'provide' 'pulp' 'put'\n",
            " 'quality' 'question' 'quigley' 'quite' 'ran' 'raptor' 'rate' 'rather'\n",
            " 'rating' 're' 'real' 'realise' 'reality' 'realized' 'realizes' 'really'\n",
            " 'reason' 'recommend' 'relationship' 'release' 'released' 'remaining'\n",
            " 'remake' 'remarkable' 'remember' 'remotely' 'rental' 'rented' 'renting'\n",
            " 'repeating' 'respect' 'rest' 'review' 'reynolds' 'richard' 'ridiculous'\n",
            " 'right' 'riley' 'rip' 'robert' 'rock' 'role' 'romance' 'romantic' 'room'\n",
            " 'rude' 'rugby' 'run' 'russel' 'russian' 'ryan' 'said' 'salesman' 'sat'\n",
            " 'save' 'saving' 'saw' 'say' 'scare' 'scarecrow' 'scared' 'scary' 'scene'\n",
            " 'scenery' 'school' 'sci' 'scientist' 'score' 'screen' 'script' 'second'\n",
            " 'see' 'seeing' 'seek' 'seem' 'seemed' 'seems' 'seen' 'self' 'sell' 'send'\n",
            " 'sense' 'sequence' 'serial' 'series' 'serio' 'serious' 'set' 'setting'\n",
            " 'several' 'sex' 'shadow' 'shah' 'shake' 'shallow' 'shame' 'shape' 'shea'\n",
            " 'sheen' 'shelf' 'ship' 'shoot' 'shooting' 'short' 'shot' 'show' 'showing'\n",
            " 'shown' 'sick' 'side' 'silly' 'similar' 'simple' 'simply' 'since'\n",
            " 'single' 'sinister' 'sister' 'sit' 'site' 'sits' 'situation' 'sketch'\n",
            " 'slap' 'sleep' 'slow' 'small' 'smith' 'soap' 'social' 'society' 'solves'\n",
            " 'someone' 'something' 'sometimes' 'somewhere' 'son' 'song' 'sort' 'soul'\n",
            " 'soundtrack' 'south' 'speak' 'speaking' 'special' 'spend' 'spends'\n",
            " 'spent' 'spider' 'spirit' 'spoiler' 'spoof' 'sport' 'spot' 'spread'\n",
            " 'stand' 'standard' 'star' 'start' 'started' 'stella' 'stephen'\n",
            " 'stereotype' 'steven' 'still' 'stomach' 'stop' 'store' 'story'\n",
            " 'storyline' 'strange' 'street' 'strong' 'structure' 'stuck' 'study'\n",
            " 'stuff' 'stunt' 'stupid' 'style' 'subtitle' 'success' 'suck' 'supporting'\n",
            " 'supposed' 'sure' 'surprise' 'surprised' 'swearing' 'take' 'taken'\n",
            " 'talent' 'talented' 'talk' 'talking' 'taste' 'team' 'teeth' 'tell' 'ten'\n",
            " 'terrible' 'terror' 'the' 'theater' 'therefore' 'thing' 'think'\n",
            " 'thinking' 'this' 'though' 'thought' 'three' 'thriller' 'tiffany' 'time'\n",
            " 'tired' 'title' 'today' 'together' 'took' 'top' 'totally' 'touch' 'town'\n",
            " 'training' 'trash' 'tried' 'true' 'truly' 'try' 'trying' 'turn' 'turned'\n",
            " 'tv' 'twice' 'twist' 'twisted' 'two' 'type' 'typical' 'un' 'understand'\n",
            " 'understandable' 'understanding' 'unfortunately' 'ungar' 'uniform'\n",
            " 'uniformly' 'unique' 'unlike' 'used' 'using' 'value' 've' 'version'\n",
            " 'video' 'view' 'viewing' 'villain' 'violent' 'visual' 'voice' 'wai'\n",
            " 'wait' 'walk' 'want' 'warn' 'waste' 'wasted' 'watch' 'watched' 'watching'\n",
            " 'way' 'weak' 'week' 'weight' 'well' 'went' 'whatever' 'white' 'whole'\n",
            " 'wife' 'willy' 'win' 'wind' 'wish' 'without' 'wo' 'woman' 'wonderful'\n",
            " 'wonka' 'word' 'work' 'worked' 'working' 'worried' 'worse' 'worst'\n",
            " 'worth' 'would' 'write' 'writer' 'writing' 'wrong' 'yeah' 'year' 'yes'\n",
            " 'yet' 'young' 'younger' 'zombie']\n"
          ]
        }
      ],
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"Feature names:\", feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vol33YgEZ3dO",
        "outputId": "7e316ddf-52a1-488c-a2ad-d9832c515654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy: 1.0\n",
            "Test Accuracy: 0.8787878787878788\n",
            "Classification Report for Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.67      0.80        12\n",
            "    positive       0.84      1.00      0.91        21\n",
            "\n",
            "    accuracy                           0.88        33\n",
            "   macro avg       0.92      0.83      0.86        33\n",
            "weighted avg       0.90      0.88      0.87        33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['Preprocessed_Text'])\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logistic_regression_model = LogisticRegression()\n",
        "\n",
        "logistic_regression_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = logistic_regression_model.predict(X_train)\n",
        "y_pred_test = logistic_regression_model.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"Train Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "print(\"Classification Report for Test Data:\")\n",
        "print(classification_report(y_test, y_pred_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDTOm7uKaO3U",
        "outputId": "ecfc1863-055b-4499-8e20-7ee58bcac21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example Text: I really like Ryan Reynolds and Hope Davis and I actually had high hopes watching this last night on DVD. Mainly as I try to avoid reviews until I watch something myself and form my own opinion Big mistake! My 2 /10 is for the first segment which in fairness is actually quite decent and if they had made the movie about the characters in section 1 alone it may have risen above the 5/10 mark.Once it moved into TV 'reality show' territory it stank to high heaven. Ryan Reynolds captured the essence of an actor on the edge wonderfully but as a gay TV writer and famous games creator / devoted family man he was definitely less effective. From the blurb on the box I expected a flashback thriller along the lines of 'Memento' - unfortunately this is nowhere near that standard of movie.\n",
            "Actual Sentiment: negative\n",
            "Predicted Sentiment: negative\n",
            "-------------------------------\n",
            "Example Text: Steven what have you done you have hit an all new low. It is weird since Steven's last film shadow man was directed by the same director who did this trash. Shadow man was good this was diabolically bad so bad it wasn't even funny Steven is hardly in the movie and feels like he is in a cameo appearance and when he is in the film he is dubbed half the time anyway. As for the action well let's just say the wizard of oz had more action than this trash there is hardly any action in the film and when it does finally arrive it is boring depressing badly shot so called action scenes. Seagal hardly kills anyone unlike his over films where he goes one man army ie under siege 1 and 2 and exit wounds. the plot is so confusing with so many plot holes that it doesn't make scenes sometimes. flight of fury better be good what a shame i wasted 5 pounds on this garbage 0 out of ten better luck next time\n",
            "Actual Sentiment: negative\n",
            "Predicted Sentiment: negative\n",
            "-------------------------------\n",
            "Example Text: It's terrific when a funny movie doesn't make smile you. What a pity!! This film is very boring and so long. It's simply painfull. The story is staggering without goal and no fun.<br /><br />You feel better when it's finished.\n",
            "Actual Sentiment: negative\n",
            "Predicted Sentiment: negative\n",
            "-------------------------------\n",
            "Example Text: Wonderful film that mixes documentary and fiction in a way that makes the spectator question: what is the extent of truth in documentary films or is there such a thing as an objective documentary.\n",
            "Actual Sentiment: positive\n",
            "Predicted Sentiment: positive\n",
            "-------------------------------\n",
            "Example Text: Ayone who whines about how this movie was crap or that it had no plot must have been looking for \"Jean de Florrette\". HELLO! this film was made to be a random act of comedy and in no way involves a plot in any way shape or form. I would also like to remind these whiners that if you are going to flay the crap out of this film that they seem to be missing the point. This film is clearly made for people who don't appreciate the so called \"american humour\" which seems to me just a pile of smutty crap. The point is everyone has an opinion and you should be a bit more appreciative that some peoples sense of humour may not be in line with your own before shooting your mouth off.<br /><br />Thankyou\n",
            "Actual Sentiment: positive\n",
            "Predicted Sentiment: positive\n",
            "-------------------------------\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "random_indices = random.sample(range(len(df)), 5)\n",
        "random_examples = df.iloc[random_indices]\n",
        "\n",
        "for index, row in random_examples.iterrows():\n",
        "  example_text = row['review']\n",
        "  preprocessed_example_text = preprocess_text(example_text)\n",
        "  example_text_vectorized = tfidf_vectorizer.transform([preprocessed_example_text])\n",
        "  predicted_sentiment = logistic_regression_model.predict(example_text_vectorized)[0]\n",
        "  actual_sentiment = row['sentiment']\n",
        "  print(\"Example Text:\", example_text)\n",
        "  print(\"Actual Sentiment:\", actual_sentiment)\n",
        "  print(\"Predicted Sentiment:\", predicted_sentiment)\n",
        "  print(\"-------------------------------\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
